{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27005bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.liepin.com/zhaopin/?ckId=6pd8v4cmiuoy9f6u1mfgkss7261he9aa&fkId=1ytg86kirxja3x927bnolqlwrxin1ala&skId=1ytg86kirxja3x927bnolqlwrxin1ala&sfrom=search_job_pc&scene=suggest&key=%E5%93%81%E7%89%8C%E6%80%BB%E7%9B%91\n",
      "https://www.liepin.com/zhaopin/?ckId=hd5lrvbtehsjyj5hn5vhazj10lrjl3aa&fkId=6pd8v4cmiuoy9f6u1mfgkss7261he9aa&skId=6pd8v4cmiuoy9f6u1mfgkss7261he9aa&sfrom=search_job_pc&key=%E9%94%80%E5%94%AE%E6%80%BB%E7%9B%91&scene=input\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#爬取猎聘网招聘数据，并存入csv文件\n",
    "#author Paul Zhang\n",
    "#requests,lxml是第三方库，需要额外安装 pip install requrests/lxml\n",
    "\n",
    "import requests,csv,time\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "def get_one_page(url):\n",
    "\n",
    "    try:\n",
    "\n",
    "        headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.74 Safari/537.36 Edg/99.0.1150.46'}\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            return etree.HTML(response.text)\n",
    "\n",
    "        return None\n",
    "\n",
    "    except RequestException:\n",
    "\n",
    "        return None\n",
    "\n",
    " \n",
    "\n",
    "def parse_one_page(html):#使用xpath定位数据\n",
    "\n",
    "    global num_2\n",
    "\n",
    "    for job in html.xpath('//div[@class=\"sojob-item-main clearfix\"]'):\n",
    "\n",
    "        num_2+=1\n",
    "\n",
    "        try:\n",
    "\n",
    "            city=job.xpath('div/p/a/text()')[0].strip()\n",
    "\n",
    "            name=job.xpath('div/h3/a/text()')[0].strip()\n",
    "\n",
    "            url=job.xpath('div/h3/a/@href')[0].strip()\n",
    "            if '/a/' in str(url):\n",
    "                url='https://www.liepin.com'+str(url)\n",
    "\n",
    "            firm=job.xpath('div//p[@class=\"company-name\"]/a/text()')[0].strip()\n",
    "\n",
    "            salary=job.xpath('div/p/span/text()')[0].strip()\n",
    "\n",
    "            time=job.xpath('div//p[@class=\"time-info clearfix\"]/time/text()')[0].strip()\n",
    "\n",
    "            yield{\n",
    "\n",
    "                    '城市':city,\n",
    "\n",
    "                    '网址':url,\n",
    "                \n",
    "                    '职位':name,\n",
    "\n",
    "                    '公司':firm,\n",
    "\n",
    "                    '薪酬':salary,\n",
    "\n",
    "                    '发布时间':time,\n",
    "\n",
    "                    '页面':num_1,\n",
    "\n",
    "                    '条目':num_2\n",
    "\n",
    "                    }\n",
    "\n",
    "        except BaseException as e:\n",
    "\n",
    "            print(num_1,num_2,e)\n",
    "\n",
    "           \n",
    "\n",
    " \n",
    "\n",
    "def init_csv():#初始化csv文件，写入标题行和爬取时间等相关信息\n",
    "\n",
    "    crawl_time=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime())\n",
    "\n",
    "    with open('品质总监.csv','a',newline='') as my_csv:\n",
    "\n",
    "        my_writer=csv.writer(my_csv)\n",
    "\n",
    "        my_csv.close()\n",
    "\n",
    "    \n",
    "\n",
    "def write_to_csv(content):#写入csv文件\n",
    "\n",
    "    with open('品质总监.csv','a',newline='') as my_csv:\n",
    "\n",
    "        fieldnames= ['城市', '网址', '职位','公司','薪酬', '发布时间','页面','条目']\n",
    "\n",
    "        my_writer=csv.DictWriter(my_csv,fieldnames=fieldnames)\n",
    "\n",
    "        try:\n",
    "\n",
    "            my_writer.writerow(content)\n",
    "\n",
    "        except BaseException as e:\n",
    "\n",
    "            print(num_1,num_2,e)\n",
    "\n",
    "                \n",
    "\n",
    "def main(offset):\n",
    "\n",
    "    global num_1,num_2\n",
    "\n",
    "    num_1,num_2=num_1+1,0\n",
    "\n",
    "    \n",
    "    crawl_url=url+'&curPage='+str(offset)\n",
    "\n",
    "\n",
    "    html = get_one_page(crawl_url)\n",
    "\n",
    "    for item in parse_one_page(html):\n",
    "\n",
    "        write_to_csv(item)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def start():\n",
    "    #if __name__ == '__main__':\n",
    "   \n",
    "\n",
    "\n",
    "    for i in range(0,10):\n",
    "        init_csv()\n",
    "        main(i)\n",
    "        time.sleep(1)#避免频繁访问，被封IP\n",
    "num_1,num_2=0,0\n",
    "dic=['https://www.liepin.com/zhaopin/?ckId=6pd8v4cmiuoy9f6u1mfgkss7261he9aa&fkId=1ytg86kirxja3x927bnolqlwrxin1ala&skId=1ytg86kirxja3x927bnolqlwrxin1ala&sfrom=search_job_pc&scene=suggest&key=%E5%93%81%E7%89%8C%E6%80%BB%E7%9B%91',\n",
    "    'https://www.liepin.com/zhaopin/?ckId=hd5lrvbtehsjyj5hn5vhazj10lrjl3aa&fkId=6pd8v4cmiuoy9f6u1mfgkss7261he9aa&skId=6pd8v4cmiuoy9f6u1mfgkss7261he9aa&sfrom=search_job_pc&key=%E9%94%80%E5%94%AE%E6%80%BB%E7%9B%91&scene=input',\n",
    "    ]\n",
    "\n",
    "     ##复制网址就行,记得登录,最多一个网址400条\n",
    "\n",
    "for j in range(len(dic)):\n",
    "    url= dic[j]\n",
    "    print(url)\n",
    "    start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62825aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
